{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is the purpose of the General Linear Model (GLM)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a31b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM models allow us to build a linear relationship between the response and predictors, even though their underlying \n",
    "relationship is not linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52501085",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What are the key assumptions of the General Linear Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "he general linear model's assumptions are:-\n",
    "linearity, homoskedasticity (constant variance), normality, and independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. How do you interpret the coefficients in a GLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7534f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "The GLM coefficients only show the multiplicative change in odds ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09065e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. What is the difference between a univariate and multivariate GLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78667424",
   "metadata": {},
   "outputs": [],
   "source": [
    "The most basic difference is that univariate regression has one explanatory (predictor) variable x and multivariate \n",
    "regression has more at least two explanatory (predictor) variables x1,x2,...,xn ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c1b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Explain the concept of interaction effects in a GLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "In general, the existence of an interaction means that the effect of one variable depends on the value of the other \n",
    "variable with which it interacts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. How do you handle categorical predictors in a GLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0356939f",
   "metadata": {},
   "outputs": [],
   "source": [
    " By categorical, I mean that you have already converted the predictor to be nominal or ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9070ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. What is the purpose of the design matrix in a GLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a135fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "The purpose of the design matrix is to allow models that further constrain parameter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. How do you test the significance of predictors in a GLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "The F-Test of overall significance in regression is a test of whether or not your linear regression model provides a\n",
    "better fit to a dataset than a model with no predictor variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. What is the difference between Type I, Type II, and Type III sums of squares in a GLM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7451f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "To obtain type I SS:\n",
    "\n",
    "anova(lm(time ~ sys * topic, data=search))\n",
    "\n",
    "If the data is unbalanced, you will obtain slightly different results if you instead use:\n",
    "\n",
    "anova(lm(time ~ topic * sys, data=search))\n",
    "\n",
    "The type II SS is obtained by using the second line of output from each of the above commands (since in type I SS, the \n",
    "second component will be the second factor, after the first factor). That is, you obtain the type II SS results for topic\n",
    "from the first command, and the results for sys from the second.\n",
    "\n",
    "Type III SS in R\n",
    "\n",
    "This is slightly more involved than the type II results.\n",
    "First, it is necessary to set the contrasts option in R. Because the multi-way ANOVA model is over-parameterised, it is\n",
    "necessary to choose a contrasts setting that sums to zero, otherwise the ANOVA analysis will give incorrect results with\n",
    "respect to the expected hypothesis. (The default contrasts type does not satisfy this requirement.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea3844",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Explain the concept of deviance in a GLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13992ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "The deviance is used to compare two models – in particular in the case of generalized linear models (GLM) where it \n",
    "has a similar role to residual sum of squares from ANOVA in linear models (RSS). Suppose in the framework of the GLM, \n",
    "we have two nested models, M1 and M2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d142c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. What is regression analysis and what is its purpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292fc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression analysis is a powerful statistical method that allows you to examine the relationship between two or more \n",
    "variables of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "12. What is the difference between simple linear regression and multiple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ac507",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multiple regression is a broader class of regressions that encompasses linear and nonlinear regressions with multiple \n",
    "explanatory variables. Whereas linear regress only has one independent variable impacting the slope of the relationship, \n",
    "multiple regression incorporates multiple independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "13. How do you interpret the R-squared value in regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "In linear regression models, r squared interpretation is a goodness-fit-measure. It takes into account the strength of \n",
    "the relationship between the model and the dependent variable. Its convenience is measured on a scale of 0 – 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad440dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "14. What is the difference between correlation and regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Correlation', as the name says, it determines the interconnection or a co-relationship between the variables. \n",
    "'Regression' explains how an independent variable is numerically associated with the dependent variable. In Correlation,\n",
    "both the independent and dependent values have no difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "15. What is the difference between the coefficients and the intercept in regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e1703",
   "metadata": {},
   "outputs": [],
   "source": [
    "The simple linear regression model is essentially a linear equation of the form y = c + b*x; where y is the dependent \n",
    "variable (outcome), x is the independent variable (predictor), b is the slope of the line; also known as regression \n",
    "coefficient and c is the intercept; labeled as constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80188175",
   "metadata": {},
   "outputs": [],
   "source": [
    "16. How do you handle outliers in regression analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ca7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are many possible approaches to dealing with outliers: removing them from the observations, treating them \n",
    "(for example, capping the extreme observations at a reasonable value), or using algorithms that are well-suited for \n",
    "dealing with such values on their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "17. What is the difference between ridge regression and ordinary least squares regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge regression works with an enhanced cost function when compared to the least squares cost function. Instead of the \n",
    "simple sum of squares, Ridge regression introduces an additional 'regularization' parameter that penalizes \n",
    "the size of the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7966108",
   "metadata": {},
   "outputs": [],
   "source": [
    "18. What is heteroscedasticity in regression and how does it affect the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0509dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Heteroskedasticity refers to situations where the variance of the residuals is unequal over a range of measured values. \n",
    "When running a regression analysis, heteroskedasticity results in an unequal scatter of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffdc66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "19. How do you handle multicollinearity in regression analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18473b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Remove some of the highly correlated independent variables.\n",
    "2.Linearly combine the independent variables, such as adding them together.\n",
    "3.Partial least squares regression uses principal component analysis to create a set of uncorrelated components to \n",
    "include in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "20. What is polynomial regression and when is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a571749",
   "metadata": {},
   "outputs": [],
   "source": [
    "A polynomial regression model is a machine learning model that can capture non-linear relationships between variables \n",
    "by fitting a non-linear regression line, which may not be possible with simple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ddcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "21. What is a loss function and what is its purpose in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A loss function is a measure of how good your prediction model does in terms of being able to predict the expected \n",
    "outcome(or value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "22. What is the difference between a convex and non-convex loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "A convex function is one in which a line drawn between any two points on the graph lies on the graph or above it. \n",
    "There is only one requirement. A non-convex function is one in which a line drawn between any two points on the graph may \n",
    "cross additional points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc464e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "23. What is mean squared error (MSE) and how is it calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Mean Squared Error measures how close a regression line is to a set of data points. It is a risk function \n",
    "corresponding to the expected value of the squared error loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16116267",
   "metadata": {},
   "outputs": [],
   "source": [
    "24. What is mean absolute error (MAE) and how is it calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b72e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE is calculated as the sum of absolute errors divided by the sample size: It is thus an arithmetic average of the \n",
    "absolute errors , where is the prediction and. the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "25. What is log loss (cross-entropy loss) and how is it calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value \n",
    "between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "26. How do you choose the appropriate loss function for a given problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d7e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "One can choose the appropriate loss function for a given problem is:-Binary Classification Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "27. Explain the concept of regularization in the context of loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted \n",
    "loss function and prevent overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "28. What is Huber loss and how does it handle outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In statistics, the Huber loss is a loss function used in robust regression, that is less sensitive to outliers in data \n",
    "than the squared error loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "29. What is quantile loss and when is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae31a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "A flexible loss function that can be incorporated into any regression model to predict a certain variable quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef322f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "30. What is the difference between squared loss and absolute loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "The mean absolute error is an average of the all absolute errors. The mean absolute error is a common measure of estimate \n",
    "error in time series analysis. The mean squared error of an estimator measures the average of the squares of the errors, \n",
    "which means the difference between the estimator and estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27567fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "31. What is an optimizer and what is its purpose in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c61d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "An optimizer is an algorithm or function that adapts the neural network's attributes, like learning rate and weights. \n",
    "Hence, it assists in improving the accuracy and reduces the total loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "32. What is Gradient Descent (GD) and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0337824",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gradient Descent is the most common optimization algorithm in machine learning and deep learning. It is a first-order \n",
    "optimization algorithm. This means it only takes into account the first derivative when performing the updates on the \n",
    "parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "33. What are the different variations of Gradient Descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7f1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Three simple variants of gradient descent algorithms, namely batch gradient descent, stochastic gradient descent and\n",
    "mini-batch gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "34. What is the learning rate in GD and how do you choose an appropriate value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b52456",
   "metadata": {},
   "outputs": [],
   "source": [
    "The learning rate hyperparameter controls the rate or speed at which the model learns. Specifically, it controls the \n",
    "amount of apportioned error that the weights of the model are updated with each time they are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "35. How does GD handle local optima in optimization problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A local optimum is an extrema (maximum or minimum) point of the objective function for a certain region of the input \n",
    "space. More formally, for the minimization case x_{local} is a local minimum of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "36. What is Stochastic Gradient Descent (SGD) and how does it differ from GD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b611de",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD is stochastic in nature i.e. it picks up a “random” instance of training data at each step and then computes the \n",
    "gradient, making it much faster as there is much fewer data to manipulate at a single time, unlike Batch GD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "37. Explain the concept of batch size in GD and its impact on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3cb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through\n",
    "before the model's internal parameters are updated. The number of epochs is a hyperparameter of gradient descent that\n",
    "controls the number of complete passes through the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5bf61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "38. What is the role of momentum in optimization algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "Momentum is an extension to the gradient descent optimization algorithm that allows the search to build inertia in a \n",
    "direction in the search space and overcome the oscillations of noisy gradients and coast across flat spots of the search \n",
    "space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5764869",
   "metadata": {},
   "outputs": [],
   "source": [
    "39. What is the difference between batch GD, mini-batch GD, and SGD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch Gradient Descent can be used for smoother curves. SGD can be used when the dataset is large. Batch Gradient Descent\n",
    "converges directly to minima. SGD converges faster for larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e491e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "40. How does the learning rate affect the convergence of GD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "If the learning rate is very large we will skip the optimal solution. If it is too small we will need too many iterations\n",
    "to converge to the best values. So using a good learning rate is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "41. What is regularization and why is it used in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted \n",
    "loss function and prevent overfitting or underfitting. Using Regularization, we can fit our machine learning model \n",
    "appropriately on a given test set and hence reduce the errors in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8791c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "42. What is the difference between L1 and L2 regularization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915fd612",
   "metadata": {},
   "outputs": [],
   "source": [
    "The differences between L1 and L2 regularization:\n",
    "L1 regularization penalizes the sum of absolute values of the weights, \n",
    "whereas L2 regularization penalizes the sum of squares of the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5190d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "43. Explain the concept of ridge regression and its role in regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a06d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularization in Linear Regression\n",
    "\n",
    "It means that our model works well not only with training or test data, but also with the data it'll receive in the \n",
    "future. In summary, to achieve this, regularization shrinks the weights toward zero to discourage complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b317f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "44. What is the elastic net regularization and how does it combine L1 and L2 penalties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0541800",
   "metadata": {},
   "outputs": [],
   "source": [
    "The elastic net is a linear regression regularization technique that combines both the L1 (Lasso) and L2 (Ridge) \n",
    "regularization penalties. It is particularly useful when dealing with datasets that have high collinearity or when there \n",
    "are more predictors than observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43185ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "45. How does regularization help prevent overfitting in machine learning models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "In an overfit model, the coefficients are generally inflated. Thus, Regularization adds penalties to the parameters \n",
    "and avoids them weigh heavily. The coefficients are added to the cost function of the linear equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "46. What is early stopping and how does it relate to regularization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7004b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner with an\n",
    "iterative method, such as gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "47. Explain the concept of dropout regularization in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aae21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout is a regularization method approximating concurrent training of many neural networks with various designs. \n",
    "During training, some layer outputs are ignored or dropped at random. This makes the layer appear and is regarded as \n",
    "having a different number of nodes and connectedness to the preceding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "48. How do you choose the regularization parameter in a model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb02c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "we choose the regularization parameteras follows: on the training set, we estimate several different Ridge regressions,\n",
    "with different values of the regularization parameter; on the validation set, we choose the best model (the regularization \n",
    "parameter which gives the lowest MSE on the validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de525cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "49. What is the difference between feature selection and regularization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature selection, also known as feature subset selection, variable selection, or attribute selection. This approach\n",
    "removes the dimensions (e.g. columns) from the input data and results in a reduced data set for model inference. \n",
    "Regularization, where we are constraining the solution space while doing optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "50. What is the trade-off between bias and variance in regularized models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ab04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias Variance Tradeoff,If the algorithm is too simple (hypothesis with linear equation) then it may be on high bias and \n",
    "low variance condition and thus is error-prone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "51. What is Support Vector Machines (SVM) and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ce92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Support vector machines (SVMs) are supervised learning models that analyze data and recognize patterns, used for \n",
    "classification and regression analysis . SVM works by constructing hyperplanes in a multidimensional space that \n",
    "separates cases of different class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832df884",
   "metadata": {},
   "outputs": [],
   "source": [
    "52. How does the kernel trick work in SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e71d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kernel trick allows the inner product of mapping function instead of the data points. The trick is to identify the kernel\n",
    "functions which can be represented in place of the inner product of mapping functions. Kernel functions allow easy \n",
    "computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "53. What are support vectors in SVM and why are they important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef37546",
   "metadata": {},
   "outputs": [],
   "source": [
    "Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the \n",
    "hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will \n",
    "change the position of the hyperplane. These are the points that help us build our SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "54. Explain the concept of the margin in SVM and its impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3252b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Margin: it is the distance between the hyperplane and the observations closest to the hyperplane (support vectors). In \n",
    "SVM large margin is considered a good margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "55. How do you handle unbalanced datasets in SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "Perhaps the simplest and most common extension to SVM for imbalanced classification is to weight the C value in proportion\n",
    "to the importance of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f47446",
   "metadata": {},
   "outputs": [],
   "source": [
    "56. What is the difference between linear SVM and non-linear SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear SVMs are used for linearly separable data, whereas nonlinear SVMs and kernel SVMs are used for non-linearly \n",
    "separable data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "57. What is the role of C-parameter in SVM and how does it affect the decision boundary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e606577",
   "metadata": {},
   "outputs": [],
   "source": [
    "C parameter adds a penalty for each misclassified data point. If c is small, the penalty for misclassified points is low \n",
    "so a decision boundary with a large margin is chosen at the expense of a greater number of misclassifications ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553381e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "58. Explain the concept of slack variables in SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Slack variables are introduced to allow certain constraints to be violated. That is, certain train- ing points will be \n",
    "allowed to be within the margin. We want the number of points within the margin to be as small as possible, and of course \n",
    "we want their penetration of the margin to be as small as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "59. What is the difference between hard margin and soft margin in SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "When the data is linearly separable, and we don't want to have any misclassifications, we use SVM with a hard margin. \n",
    "However, when a linear boundary is not feasible, or we want to allow some misclassifications in the hope of achieving \n",
    "better generality, we can opt for a soft margin for our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22020534",
   "metadata": {},
   "outputs": [],
   "source": [
    "60. How do you interpret the coefficients in an SVM model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "The weights obtained from svm. coef_ represent the vector coordinates which are orthogonal to the hyperplane and their \n",
    "direction indicates the predicted class. The absolute size of the coefficients in relation to each other can then be used \n",
    "to determine feature importance for the data separation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "61. What is a decision tree and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a39e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and \n",
    "regression tasks. It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and \n",
    "leaf nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfaaeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "62. How do you make splits in a decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "The most widely used method for splitting a decision tree is the gini index or the entropy. The default method used in \n",
    "sklearn is the gini index for the decision tree classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddcdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "63. What are impurity measures (e.g., Gini index, entropy) and how are they used in decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "The node impurity is a measure of the homogeneity of the labels at the node. The current implementation provides two \n",
    "impurity measures for classification (Gini impurity and entropy) and one impurity measure for regression (variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a6e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "64. Explain the concept of information gain in decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5663c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Information gain is the basic criterion to decide whether a feature should be used to split a node or not. The feature \n",
    "with the optimal split i.e., the highest value of information gain at a node of a decision tree is used as the feature \n",
    "for splitting the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "65. How do you handle missing values in decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44bcabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surrogate splitting rules enable you to use the values of other input variables to perform a split for observations \n",
    "with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b75b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "66. What is pruning in decision trees and why is it important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfbf16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A Decision tree that is trained to its full depth will highly likely lead to overfitting the training data - therefore\n",
    "Pruning is important. In simpler terms, the aim of Decision Tree Pruning is to construct an algorithm that will perform\n",
    "worse on training data but will generalize better on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed53fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "67. What is the difference between a classification tree and a regression tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a79b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are 2 types of Decision trees: Classification trees are used when the dataset needs to be split into classes that \n",
    "belong to the response variable. Regression trees, on the other hand, are used when the response variable is continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651bfe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "68. How do you interpret the decision boundaries in a decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c9318",
   "metadata": {},
   "outputs": [],
   "source": [
    "The first node of the tree called the “root node” contains the number of instances of all the classes respectively.\n",
    "Basically, we have to draw a line called “decision boundary” that separates the instances of different classes into \n",
    "different regions called “decision regions”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f52e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "69. What is the role of feature importance in decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebcd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A decision tree is explainable machine learning algorithm all by itself. Beyond its transparency, feature importance is \n",
    "a common way to explain built models as well. Coefficients of linear regression equation give a opinion about feature \n",
    "importance but that would fail for non-linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "70. What are ensemble techniques and how are they related to decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5824aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Using one decision tree is can be problematic and might not be stable enough; however, using multiple decision trees and \n",
    "combining their results will do great. Combining multiple classifiers in a prediction model is called ensembling. \n",
    "The simple rule of ensemble methods is to reduce the error by reducing the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aeb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "71. What are ensemble techniques in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb39979",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble methods are techniques that create multiple models and then combine them to produce improved results. Ensemble\n",
    "methods in machine learning usually produce more accurate solutions than a single model would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "72. What is bagging and how is it used in ensemble learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37207d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging, also known as Bootstrap aggregating, is an ensemble learning technique that helps to improve the performance \n",
    "and accuracy of machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "73. Explain the concept of bootstrapping in bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0768dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging leverages a bootstrapping sampling technique to create diverse samples. This resampling method generates \n",
    "different subsets of the training dataset by selecting data points at random and with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "74. What is boosting and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "In boosting, a random sample of data is selected, fitted with a model and then trained sequentially—that is, each model \n",
    "tries to compensate for the weaknesses of its predecessor. With each iteration, the weak rules from each individual\n",
    "classifier are combined to form one, strong prediction rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaeb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "75. What is the difference between AdaBoost and Gradient Boosting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e6327",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost is the first designed boosting algorithm with a particular loss function. On the other hand, Gradient Boosting \n",
    "is a generic algorithm that assists in searching the approximate solutions to the additive modelling problem. This makes \n",
    "Gradient Boosting more flexible than AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "76. What is the purpose of random forests in ensemble learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "A random forest is a machine learning technique that's used to solve regression and classification problems. It utilizes \n",
    "ensemble learning, which is a technique that combines many classifiers to provide solutions to complex problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "77. How do random forests handle feature importance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6106742",
   "metadata": {},
   "outputs": [],
   "source": [
    "The final feature importance, at the Random Forest level, is it's average over all the trees. The sum of the feature's \n",
    "importance value on each trees is calculated and divided by the total number of trees: RFfi sub(i)= the importance of \n",
    "feature i calculated from all trees in the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3649f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "78. What is stacking in ensemble learning and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stacking is one of the most popular ensemble machine learning techniques used to predict multiple nodes to build a new \n",
    "model and improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "79. What are the advantages and disadvantages of ensemble techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bdc629",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble methods offer several advantages over single models, such as improved accuracy and performance, especially for \n",
    "complex and noisy problems. They can also reduce the risk of overfitting and underfitting by balancing the trade-off \n",
    "between bias and variance, and by using different subsets and features of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcee3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "80. How do you choose the optimal number of models in an ensemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 1 : Find the KS of individual models. ...\n",
    "Step 2: Index all the models for easy access. ...\n",
    "Step 3: Choose the first two models as the initial selection and set a correlation limit. ...\n",
    "Step 4: Iteratively choose all the models which are not highly correlated with any of the any chosen model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
